<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Natural Language Processing on LIU Yun-Chung</title>
    <link>https://halfmoonliu.github.io/tags/natural-language-processing/</link>
    <description>Recent content in Natural Language Processing on LIU Yun-Chung</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 05 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://halfmoonliu.github.io/tags/natural-language-processing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Train Word Embeddings with CBOW Model (Link)</title>
      <link>https://halfmoonliu.github.io/posts/train-word-embeddings-with-cbow-model-link/</link>
      <pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://halfmoonliu.github.io/posts/train-word-embeddings-with-cbow-model-link/</guid>
      <description>&lt;p&gt;Word Embedding is an effective way to represent relationship between words. Words with similar neighbors (context) have similar embeddings. In the now well-known paper published by Mikolov et al (2013), they demonstrated how to use continuous bag-of-words (CBOW) model to train word embeddings, which can be applied to analogy and other downstream tasks. This project uses Numpy to train word embeddings using CBOW model from scratch and apply on analogy task.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Use BiLSTM for Name Entity Recognition (Link)</title>
      <link>https://halfmoonliu.github.io/posts/use-bilstm-for-name-entity-recognition-link/</link>
      <pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://halfmoonliu.github.io/posts/use-bilstm-for-name-entity-recognition-link/</guid>
      <description>&lt;p&gt;Name Entity Recognition (NER) is a natural language processing task to categorize words into name entities, which has many applications (e.g. searching). Here is a demo of how I trained a bi-Directional Long-Short Term Memory (BiLSTM) model to predict name entities with accuracy of over .95 using CONRLL 2003 dataset.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
