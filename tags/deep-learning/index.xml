<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on LIU Yun-Chung</title>
    <link>https://halfmoonliu.github.io/tags/deep-learning/</link>
    <description>Recent content in Deep Learning on LIU Yun-Chung</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 05 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://halfmoonliu.github.io/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Train Word Embeddings with CBOW Model (Link)</title>
      <link>https://halfmoonliu.github.io/posts/train-word-embeddings-with-cbow-model-link/</link>
      <pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://halfmoonliu.github.io/posts/train-word-embeddings-with-cbow-model-link/</guid>
      <description>&lt;p&gt;Word embedding is an effective way to represent the relationship between words. Words with similar neighbors (i.e. context) have similar embeddings. In a now well-known paper published by Mikolov et al. (2013), they demonstrated how to use the continuous bag-of-words (CBOW) model to train word embeddings, which can be applied to analogy and other downstream tasks. This project uses NumPy to train word embeddings by using the CBOW model from scratch and applying them to an analogy task.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Use BiLSTM for Name Entity Recognition (Link)</title>
      <link>https://halfmoonliu.github.io/posts/use-bilstm-for-name-entity-recognition-link/</link>
      <pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://halfmoonliu.github.io/posts/use-bilstm-for-name-entity-recognition-link/</guid>
      <description>&lt;p&gt;Name Entity Recognition (NER) is a natural language processing task for categorizing words into name entities with numerous applications (e.g., searching, text classification, etc.). The following is a demo on how I trained a Bi-directional Long-Short Term Memory (BiLSTM) model to predict name entities with an accuracy of over .95 using the CoNLL-2003 Dataset.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Evaluate Intensive Care Needs with ML (Link)</title>
      <link>https://halfmoonliu.github.io/posts/evaluate-intensive-care-needs-with-ml-link/</link>
      <pubDate>Tue, 19 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://halfmoonliu.github.io/posts/evaluate-intensive-care-needs-with-ml-link/</guid>
      <description>&lt;p&gt;Machine learning (ML) can be used by hospitals to improve the quality of healthcare. The purpose of this post is to demonstrate the steps necessary to build ML models that evaluate the need for intensive care within the first 24 hours of hospital admission. This post includes the workflow process of data cleansing, feature engineering, and model building, which can be applied directly to real-world settings.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
