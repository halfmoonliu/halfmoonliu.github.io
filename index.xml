<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LIU Yun-Chung</title>
    <link>https://halfmoonliu.github.io/</link>
    <description>Recent content on LIU Yun-Chung</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 10 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://halfmoonliu.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Machine Translation Using Transformer Models</title>
      <link>https://halfmoonliu.github.io/posts/machine-translation-using-transformer-models/</link>
      <pubDate>Wed, 06 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://halfmoonliu.github.io/posts/machine-translation-using-transformer-models/</guid>
      <description>&lt;p&gt;One of recent breakthroughs in machine translation is the application of the transformer. Compared with the sequence-to-sequence model based on recurrent neural networks (RNN), the attention-based transformer model makes use of encoder output at every time step, which further enhances machine translation performances. In this post, I will walk through the structure of RNN- and transformer-based and machine translation models, steps to build them and compare their performances.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Train Word Embeddings with CBOW Model</title>
      <link>https://halfmoonliu.github.io/posts/train-word-embeddings-with-cbow-model/</link>
      <pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://halfmoonliu.github.io/posts/train-word-embeddings-with-cbow-model/</guid>
      <description>&lt;p&gt;Word embedding is an effective way to represent the relationship between words. Words with similar neighbors (i.e. context) have similar embeddings. In a now well-known paper published by Mikolov et al. (2013), they demonstrated how to use the continuous bag-of-words (CBOW) model to train word embeddings, which can be applied to analogy and other downstream tasks. This project uses NumPy to train word embeddings by using the CBOW model from scratch and applying them to an analogy task.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Use BiLSTM for Name Entity Recognition</title>
      <link>https://halfmoonliu.github.io/posts/use-bilstm-for-name-entity-recognition/</link>
      <pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://halfmoonliu.github.io/posts/use-bilstm-for-name-entity-recognition/</guid>
      <description>&lt;p&gt;Name Entity Recognition (NER) is a natural language processing task for categorizing words into name entities with numerous applications (e.g., searching, text classification, etc.). The following is a demo on how I trained a Bi-directional Long-Short Term Memory (BiLSTM) model to predict name entities with an accuracy of over .95 using the CoNLL-2003 Dataset.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Evaluate Intensive Care Needs with ML</title>
      <link>https://halfmoonliu.github.io/posts/evaluate-intensive-care-needs-with-ml/</link>
      <pubDate>Tue, 19 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://halfmoonliu.github.io/posts/evaluate-intensive-care-needs-with-ml/</guid>
      <description>&lt;p&gt;Machine learning (ML) can be used by hospitals to improve the quality of healthcare. The purpose of this post is to demonstrate the steps necessary to build ML models that evaluate the need for intensive care within the first 24 hours of hospital admission. This post includes the workflow process of data cleansing, feature engineering, and model building, which can be applied directly to real-world settings.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wine Recommendation Using the Aroma Wheel</title>
      <link>https://halfmoonliu.github.io/posts/wine-recommendation-using-the-aroma-wheel/</link>
      <pubDate>Sun, 22 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://halfmoonliu.github.io/posts/wine-recommendation-using-the-aroma-wheel/</guid>
      <description>&lt;p&gt;In this project, I took a modified version of the famous aroma wheel and used word-count to represent the characteristics of French wine. Donâ€™t know how to choose a bottle of wine? Check out your favorite aroma!&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
